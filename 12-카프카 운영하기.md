---
title: 12-카프카 운영하기
tags:
  - 도서/카프카-핵심-가이드
---
## 토픽 작업

- 토픽 작업을 쉽게할 수 있는 툴은 `kafka-topics.sh`이다.
	- 역할: 클러스터 내 토픽 생성, 변경, 삭제, 정보 조회
	- 토픽 설정 변경은 `kafka-topics.sh`에서는 지원 중단 되었으니, 더 강력한 툴인 `kafka-configs.sh`를 사용하는 것이 좋다.
- `kafka-topics.sh`를 사용하려면 `--bootstrap-server` 옵션에 연결 문자열과 포트를 넣어 줘야한다.
- 이 장 전체에 걸쳐 모든 툴이 저장된 위치는 `/usr/local/kafka/bin/` 디렉토리다.

### 새 토픽 생성하기

- `--create` 명령을 사용해서 새로운 토픽을 생성할 수 있다.
- 생성할 떄는 3개의 필 수 인수가 있다.
	- `--topic`: 생성하려는 토픽의 이름
	- `--replication-factor`: 클러스터 안에 유지되어야 할 레플리카의 개수
	- `--partitions`: 토픽에서 생성할 파티션의 개수
- 토픽 이름 짓기
	- 토픽 이름에는 영문, 숫자, `_`, `-`, `.`를 사용할 수 있지만, `.`를 사용하는 것을 권장하지 않는다.
		- 이유: 카프카에서 내부적으로 사용하는 지표에서 `.`를 `_`로 변환해서 처리한느 탓에 토픽 이름에 충돌이 발생할 수 있기 때문이다.
	- 토픽 이름을 `__`로 시작하는 것을 권장하지 않는다.
		- 카프카 내부에서 사용되는 토픽을 생성할 때 `__`로 시작하는 이름을 쓰느 것이 관례이기 때문이다.
- ![](assets/Pasted%20image%2020250817121145.png)
- 클러스터에 랙 인식 레플리카 할당 설정이 되어 있을 경우, 각 파티션의 레플리카는 서로 다른 랙에 위치하게 된다.
	- 랙 인식 할당 기능을 사용하지 않으려면 `--disable-rack-aware` 인수를 지정해주면 된다.

### 토픽 목록 조회하기

- `--list` 명령을 사용해서 클러스터 안의 모든 토픽을 보여준다.
	- 이떄 출력되는 결과는 한 줄에 하나의 토픽이며, 특정한 순서는 없다.
- ![](assets/Pasted%20image%2020250817121449.png)
	- `--exclude-internal`와 함꼐 실행하면 `__`로 시작하는 내부 토픽은 제외하고 보여준다.

### 토픽 상세 내역 조회하기

- 하나의 토픽에 대해서만 보고 싶다면 `--topic` 인수를 지정해주면 된다.
	- ![](assets/Pasted%20image%2020250817122135.png)
- 필터링 할 몇몇 옵션을 기준으로 토픽 상세 조회를 하고싶다면 `--describe` 명령을 사용하면 된다. 아래는 자주 사용하는 옵션이다.
	- `--topics-with-overrides`: 설정 중 클러스터 기본값을 재정의한 것이 있는 토픽들을 보여준다.
	- `--exclude-internal`: `__`로 시작하는 모든 토픽들을 결과에서 제외한다.
	- `--under-replicated-partitions`: 1개 이상의 레플리카가 리더와 동기화되지 않고 있는 모든 파티션을 보여준다.
	- `--at-min-isr-partitions`: 레플리카 수(리더 포함)가 인-싱크 레플리카 최소값과 같은 모든 파티션을 보여준다. 이 토픽들은 프로듀서나 컨슈머 클라이언트가 여전히 사용할 수 있지만 중복 저장된 게 없기 때문에 작동 불능에 빠질 위험이 있다.
	- `--under-min-isr-partitions`: ISR 수가 쓰기 작업이 성공하기 위해 필요한 최소 레플리카 수에 미달하는 모든 파니션을 보여준다. 이 파티션들은 사실상 읽기 전용 모드라고 할 수 있고, 쓰기 작업은 불가능하다.
	- `--unavailable-partitions`: 리더가 없는 모든 파티션을 보여준다. 이것은 매우 심각한 상황이므로, 파티션이 오프라인 상태이며 프로듀서나 컨슈머 클라이언트가 사용 불간으하다는 것을 의미한다.
	- ![](assets/Pasted%20image%2020250817122616.png)

### 파티션 추가하기

- 파티션 수를 증가시키는 가장 일반적인 이유는 단일 파티션에 쏟아지는 처리량을 줄임으로써 토픽을 더 많은 브로커에 대해 수평적으로 확장시키기 위해서이다.
- `--alter` 명령과 `--partitions` 로 파팃녕르 증가시킬 수 있다.
	- ![](assets/Pasted%20image%2020250817123321.png)
- 키가 있는 메시지를 갖는 토픽에 파티션을 추가하는 것으 매우 어려울 수 있다.
	- 이유: 파티션의 수가 변하면 키값에 대응되는 파티션 달라지기 때문이다.
	- 결론: 키가 포함된 메시지를 저장하는 토픽을 생성할 때는 미리 파티션의 개수를 정해 놓고, 일단 생성한 뒤에는 설정한 파티션의 수를 바꾸지 않는 것이 좋다.

### 파티션 개수 줄이기

- 토픽의 파티션 개수를 줄일 수 없다.
	- 이유1: 토픽에서 파티션을 삭제한다는 것은 곧 토픽에 저장된 데이터 일부를 삭제한다는 의미인데, 클라이언트 입장에서 일관적이지 않아 보일 수 있다.
	- 이유2: 데이터에 남은 파티션에 다시 분배하는 것은 어려울 뿐 아니라 메시지의 순서를 바꾸게 된다.
- 만약 파티션의 수를 줄여야 한다면, 토픽을 삭제하고 다시 만들거나 새로운 버전의 토픽을 생성해서 모든 쓰기 트래픽을 새 토픽으로 몰아주는 것을 권장한다.

### 토픽 삭제하기

- 토픽 삭제 이유: 메시지가 하나도 없는 토픽이라 할지라도 디스크 공간이나 파일 핸들, 메모리와 같은 클러스터 자원을 잡아먹는다.
- 토픽을 삭제하기 위해서는 클러스터 브로커의 `delete.topic.enable` 옵션이 true로 설정되어 있어야 한다.
	- false라면 삭제 요청은 무시되어 아무 처리가 이뤄지지 않을 것이다.
- 토픽 삭제는 비동기적인 작업이다.
	- 상세 동작: 컨트롤러가 가능하면 빨리 브로커에 아직 계류중인 삭제 작업에 대해 통지하면, 브로커는 해당 토픽에 대한 메타데이터를 무효화한 뒤 관련된 파일을 디스크에서 지우게 된다.
- 컨트롤러가 삭제 작업을 처리하는 방식 한계 대문에 토픽을 지울 때는 2개 이상의 토픽을 동시에 삭제하지 말고 삭제 작어 ㅂ사잉 ㅔ충분한 시간을 둘 것을 권장한다.
- `--delete` 인수를 통해서 토픽을 삭제할 수 있다.
- 삭제가 성공했는지 확인하려면 `--list`나 `--describe` 옵션을 사용해서 클러스터 내 토픽이 더 이상 존재하지 않는다는 걸 확인하면 된다.

## 컨슈머 그룹

- `kafka-consumer-groups.sh` 툴을 사용하면 클러스터에서 토픽을 읽고 있는 컨슈머 그룹을 관리할 수 있다.
	- 역할: 그룹 상세 내역 조회, 삭제, 오피슷 정보 초기화 등

### 컨슈머 그룹 목록 및 상세 내역 조회하기

- 컨슈머 그룹 목록 보기: `--bootstrap-server`와 `--list` 매개변수를 사용하면 된다.
	- `kafka-consumer-groups.sh` 스크립트를 사용할 경우, 컨슈머 목록에 `console-consumer-{생성된 ID}`로 보인다.
	- ![](assets/Pasted%20image%2020250817134503.png)
- 목록에 포함된 모든 그룹에 대해서 `--list` 매개변수를 `--describe`로 바꾸고 `--group` 매개변수를 추가함으로써 상세한 정보를 조회할 수 있다.
	- ![](assets/Pasted%20image%2020250817134650.png)
	- ![](assets/Pasted%20image%2020250817134657.png)

### 컨슈머 그룹 삭제하기

- `--delete` 매개변수를 사용하면 컨슈머 그룹 삭제가 가능하다.
	- 동작: 그룹이 읽고 있는 모든 노픽에 대해 저장된 모든 오프셋을 포함한 전체 그룹을 삭제한다.
- 이 작업을 수행하려면 컨슈머 그룹 내의 모든 컨슈머들이 모두 내려간 상태여서 컨슈머 그룹에 활동중인 멤버가 없어야 한다.
	- 만약 비어 있지 않은 그룹을 삭제하려고 시도할 경우, "The group is not empty"라는 에러가 발생하고 아무 작업도 수행되지 않을 것이다.
- `--topic` 매개변수에 삭제하려는 토픽의 이름을 지정함으로써 컨슈머 그룹 전체를 삭제하는 대신에 컨슈머 그룹이 읽어오고 있는 특정 토픽에 대한 오프셋만 삭제하는 것도 가능하다.
- ![](assets/Pasted%20image%2020250817135055.png)

### 오프셋 관리

- 컨슈머 그룹에 대한 오프셋들을 조회, 삭제, 가져오기, 저장이 가능하다.
- 오프셋 내보내기
	- 설명: 컨슈머 그룹을 csv 파일로 내보내려면 `--dry-run` 옵션과 함께 `--reset-offsets` 매개벼누를 사용해주면 된다.
	- CSV 파일 형식: `{토픽 이름},{파티션 번호},{오프셋}`
	- `--dry-run` 없이 같은 명령을 실행하면 오프셋이 완전히 리셋되니 주의해야된다.
	- ![](assets/Pasted%20image%2020250817142730.png)
- 오프셋 가져오기
	- 설명: 앞에서 설명한 내보내기 작업에서 생성된 파일을 가져와서 컨슈머그룹의 현재 오프셋을 설정하는 데 사용한다.
		- 이 기능은 대체로 현새 컨슈머 그룹의 오프셋을 내보낸 뒤, 백업을 하기 위한 복사본을 만들어 놓고, 오프셋을 원하는 값으로 바꿔서 사용하는 식으로 운용한다.
	- 오프셋 가져오기를 하기 전에 컨슈머 그룹에 속한 모든 컨슈머를 중단시키는 것이 중요하다.
		- 이유: 컨슈머 그룹이 현재 돌아가고 있는 상태에서 새 오프셋을 넣어 준다고 해서 컨슈머가 새 오프셋 값을 읽어오지는 않기 때문이다. 이 경우 컨슈머는 그냥 새 오프셋들을 덮어써 버린다.
		- ![](assets/Pasted%20image%2020250817143127.png)

## 동적 설정 변경

- `kafka-configs.sh`로 토픽, 클라이언트, 브로커 등 많은 설정이 클러스터를 끄거나 재설치할 필요없이 돌아가는 와중이 동적으로 바꿀 수 있는 설정이 많다.
- 현재 동적으로 변경이 가능한 설정의 범주는 4가지가 잇다.
	- 토픽, 브로커, 사용자, 클라이언트
- 이러한 설정 작업을 자동화하기 위해 관리하고자 하는 설정을 밀 ㅣ형식에 맞춰 담아 놓은 파일과 `--add-config-file`인자를 사용할 수 있다.

## 토픽 설정 기본값 재정의하기

- 토픽 설정을 변경하기 위한 명령 형식은 다음과 같다.
	- `bin/kafka-configs.sh --botstrap-server localhost:9092 --alter --entity-type topics --entity-name {토픽 이름} --add-config {key}={value}[, {key}={value}...]`

### 클라이언트와 사용자 설정 기본값 재정의하기

- 카프카 클라이언트와 사용자의 경우, 재정의 가능한 설정은 쿼터에 관련된 것 몇 개밖에 없다.
- 가장 일반적인 설정 두 개은 특정 클라이언트 ID에 대해 브로커별로 설정되는 프로듀서와 컨슈머 bytes/sec 속도다.

### 브로커 설정 기본값 재정의하기

- 동적으로 재정의 가능한 브로커 설정은 80개가 넘는다.
- 특별히 짚어볼 중요한 설정은 다음과 같다.
	- `min.insync.replicas`: 프로듀서의 acks 설정값이 `all`로 잡혀 있을 때 쓰기 요청에 응답이 가기 전에 쓰기가 이루어져야 하는 레플리카 수의 최소값을 결정한다.
	- `unclean.leader.election.enable`: 리더로 선출되었을 경우 데이터 유실이 발생하는 레플리카를 리더로 선출할 수 있게 한다. 약간의 데이터 유실이 허용되는 경우 혹은 데이터 유실을 피할 수 없어서 카프카 클러스터의설정을 잠깐 풀어주거나 해야 할 때 유용하다.
	- `max.connections`: 브로커에 연결할 수 있는 최대 연결 수. 좀 더 정밀한 스로틀링 바란다면 `max.connections.per.ip.max.connections.per.ip.overrides`를 사용할 수 있다.

### 재정의된 설정 상세 조회하기

- 다른 툴들과 마찬가지로 `--describe` 명령을 사용하면 된다.
	- ![](assets/Pasted%20image%2020250817150310.png)
- 이 툴은 재정의된 설정값을 보여줄 뿐, 클러스터 기본값을 따르는 설정은 포함하지 않는다.

### 재정의된 설정 삭제하기

- 재정의된 설정을 삭제하려면 `--delete-config` 매개변수와 함께 `--alter` 명령을 사용한다.
- ![](assets/Pasted%20image%2020250817150518.png)

## 쓰기 작업과 읽기 작업

- 수동으로메시지를 쓰거나 샘플 메시지를 읽어와야 하는 경우, `kafka-console-consumer.sh`와 `kafka-console-producer.sh`를 사용할 수 있다.
	- 이 툴들은 자바 클라이언트 라이브러리를 살짝 감싸는 형태로 구현되었으며, 해당 작업을 수행하는 애플리케이션 전첼르 작성할 필요 없이 카프카 토픽과 상호작용할 수 있도록 해 준다.

### 콘솔 프로듀서

- 메시지는 줄 단위로, 키와 밸류값은 탭 문자를 기준으로 구분된다.(탭 문자가 없으면 키값은 null이 된다)
- 콘솔 프로듀서는 기본 시리얼라이저를 사용해서 읽어들인 데이터를 바이트 뭉치로 변환한다.
- 콘솔 프로듀서를 사용할 떄는 어느 카프카 클러스터에 연결할지, 그 클러스터의 어느 토픽에 쓸지를 정의하는 인수 두 개를 반드시 지정해주어야 한다.
- 쓰기 작업이 끝났다면 end-of-file(EOF) 문자를 입력해서 클라이언트를 종료시키자. 대부분의 터미널에서는 Ctrl + D로 가능하다.
	- ![](assets/Pasted%20image%2020250817151610.png)
- 프로듀서 설정 옵션 사용하기
	- 프로듀서를 설정할 때 사용하는 설정을 콘솔 프로듀서에 전달하는 방법은 2가지다.
		- 방법1: `--producer.config {설정파일}`을 지정하는 방법
		- 방법2: 명령줄에서 1개 이상의 `--producer-property {키}={값}` 인수를 지정하는 방법
	- 대표적인 설정
		- `--batch-size`: (비동기 모드로 작동 중일 때) 하나의 배치로 전달되어야 할 메시지의 수를 지정한다.
		- `--timeout`: (비동기 모드로 작동 중일 때) 메시지 배치를 쓰기전에 기다리는 최대 시간을 지정ㅎㄴ다.
		- `--compression-codec {압축 코덱}`: 메시지를 쓸 때 사용할 압축 코덱을 지정한다. none, gzip(기본값), snappy, zstd, lz4 중 하나를 사용할 수 있다. 
		- `--sync`: 메시지를 동기적으로 쓴다.
- 읽기 옵션
	- 표준 입력으로 들어온 값을 읽어서 프로듀서 레코드를 생성하는 `LineMessageReader` 클래스 역시 옵션을 가지고 있다.
	- 콘솔 프로듀서에 `--property` 명령줄 옵션을 사용해서 지정 가능하다.
	- 옵션
		- `ignore.error`: 이 값이 false이고 `parse.key`가 true인 상태에서 키 구분자가 정의되어 있지 않을 경우 에외가 발생한다. 기본값은 true다.
		- `parse.key`: 킥값을 항상 null로 고정하고 싶다면 flase로 잡아주면 된다. 기본값은 true다.
		- `key.separator`: 메시지 키와 밸류를 구분할 때 사용되는 구분자로서 기본값은 탭 문자다.

### 콘솔 컨슈머

- 기본적으로 키나 형식 같은 것 없이 메시지 안에 저장된 raw bytes 뭉치가 출력된다.(출력 형식은 `DefaultFormatter`이 결정한다)
- 어떤 토픽으로부터 메시지를 읽어올지를 결정하는 옵션은 두 개가 있다.
	- `--topic`: 읽어올 토픽의 이름을 지정한다(1개).
	- `--whitelist`: 읽어오고자 하는 모든 토픽 이름과 매치되는 정규식을 지정한다.
- 콘솔 컨슈머가 일단 시작되면 쉘 이스케이프 명령이 주어지기 전까지 계속해서 메시지를 읽어온다.
	- ![](assets/Pasted%20image%2020250817153256.png)

- 컨슈머 설정 옵션 사용하기
	- 설정을 콘솔 컨슈머에게 전달 하는 방법 2가지
		- 방법1: `--consumer.config {설정 파일}`
		- 방법2: 명령줄에서 1개 이상의 `--consumer-property {키}={값}` 형태의 인수를 옵션으로 지정
	- 대표적인 옵션
		- `--formatter {클래스 이름}`: 메시지를 바이트 뭉치에서 문자열로 변환하기 위해 사용될 메시지 포매터 클래스를 지정한다. 기본값은 `kafka.tools.DefaultMessageFormatter`다.
		- `--from-beginning`: 지정된 토픽의 가장 오래된 오프셋부터 메시지를 읽어온다.
			- 이를 지정하지 않으면 가장 최근 오프셋부터 읽어온다.
		- `--max-messages {정수값}`: 종료되기 전에 읽어올 최대 메시지 수
		- `--partition {정수값}`: 지정된 ID의 파티션에서만 읽어온다.
		- `--offset`: 읽어오기 시작할 오프셋. `earliest`로 지정한 경우 맨 처음부터 `latest`로 지정할 경우 가장 최신값부터 읽어온다.
		- `--skip-message-on-error`: 메시지에 에러가 있을 경우 실행을 중단한느 게 아니라 그냥 넘억나다. 디버깅할 떄 좋다.
- 메시지 포매터 옵션: 기본값 외에 사용 가능한 메시지 포매터는 3개다.
	- `kafka.tools.LoggingMessageFormatter`: 표준 출력이 아니라 로거를 사용해서 메시지를 출력한다. 각 메시지는 INFO 레벨로 출력되며, 타임스탬피, 키, 밸류를 포함한다.
	- `kafka.tools.ChecksumMessageFormatter`: 메시지의 체크섬만 출력한다.
	- `kafka.tools.NoOpMessageFormatter`: 메시지를 읽어오되 아무것도 출력하지 않는다.
	- ![](assets/Pasted%20image%2020250817154312.png)
	- `kafka.tools.DefaultMessageFormatter` 역시 `--property` 명령줄 옵션으로 여러 유용한 옵션을 전달할 수 있다.
		- ![](assets/Pasted%20image%2020250817154348.png)

- 오프셋 토픽 읽어오기
	- 클러스터의 컨슈머 그룹별로 커밋된 오프셋을 확인해봐야 하는 경우가 있다. 이 때, 콘솔 컨슈머를 사용해서 `__consumer_offsets` 내부 토픽을 읽어오면 된다.
	- 이 토픽에 저장된 메시지를 열어보고 싶다면 `kafka.coordinator.group.GroupMetadatamanager$OffsetsMessageFormatter` 포매터 클래스를 사용하자.
	- ![](assets/Pasted%20image%2020250817154556.png)
